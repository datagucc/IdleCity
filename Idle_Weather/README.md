# ğŸŒ¤ï¸ Open-Meteo Datalake Project


## ğŸŒ Overview
This first phase of the project focuses on climate analysis.
This first phase is a complete Data Engineering pipeline focused on extracting, processing, and storing weather data from the Open-Meteo API. It follows modern data lakehouse architecture principles and is structured around three layers: Bronze (raw), Silver (cleaned), and Gold (aggregated).

---

## ğŸ“¡ Data Source

ğŸŒ¦ï¸ **Open-Meteo API**: A free, no-authentication-required API that provides rich weather data including:

- Geolocation  
- Current weather  
- Forecast (daily and hourly)  
- Historical weather  

---

## ğŸ—ï¸ Architecture: Bronze, Silver, Gold

### ğŸ¥‰ Bronze Layer
- Extracts raw weather data from Open-Meteo API endpoints.  
- Saves the data without transformation in Delta Lake format.  
- Maintains source fidelity  
- Monitors the data with metadata_table and logs table  

### ğŸ¥ˆ Silver Layer
- Cleans and standardizes data (column renaming, types, structure).  
- Deduplicates and validates records.  
- Stores clean datasets in Delta format for analytical use.  
- Monitors the data with metadata_table and logs table  

### ğŸ¥‡ Gold Layer
- Aggregates, filters, and derives KPIs (e.g., average temperatures, daily summaries).  
- Prepares final tables for analytics, dashboards, or machine learning pipelines.  
- Monitors the data with metadata_table and logs table  

---

## ğŸš€ Usage

### Installing Dependencies
1. Install all required modules by running the following command:

```bash
pip install -r Config/requirements.txt


## ğŸš€ Running the Pipeline

1. Through Notebooks: `almacenamiento_bronze`, `almacenamiento_silver`, and `almacenamiento_gold` (in the `notebooks/` folder)

2. Through the script `main.py`, which calls the 3 scripts: `bronze_layer.py`, `silver_layer.py`, and `gold_layer.py`.

---

## ğŸ“Š Pipeline Workflow

1. **ğŸ”„ Data Extraction**  
   The `almacenamiento_bronze.ipynb` notebook (or the script) extracts data from APIs and stores it in `data/bronze`.

2. **âš™ï¸ Data Transformation**  
   `almacenamiento_silver.ipynb` (or the script) cleans and structures the data before storing it in `data/silver`.

3. **ğŸ’¡ Insights Creation**  
   `almacenamiento_gold.ipynb` (or the script) computes new columns, cross tables for further analysis before storing it in `data/gold`.

4. **ğŸ”§ Modular Design**  
   The pipeline relies on Python modules from `modules/`, ensuring **modularity** and **reusability**.

---

## ğŸ“ Project Structure

Entrega_Final/
â”‚
â”œâ”€â”€ config/                      # Configuration files (e.g., API URLs, parameters)
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ data/                        # Data lake folders
â”‚   â”œâ”€â”€ bronze/                  # Raw Delta tables
â”‚   â”œâ”€â”€ silver/                  # Cleaned Delta tables
â”‚   â”œâ”€â”€ gold/                    # Aggregated/analytical Delta tables
â”‚   â””â”€â”€ _meta/                   # Central metadata table + Excel exports
â”‚
â”œâ”€â”€ logs/                        # Execution logs and error logs
â”‚   â””â”€â”€
â”‚
â”œâ”€â”€ modules/                     # Custom Python modules
â”‚   â”œâ”€â”€ openmeteo_api.py         # API calls (current, forecast, historical)
â”‚   â”œâ”€â”€ DF_functions.py          # DataFrame cleaning utilities
â”‚   â”œâ”€â”€ metadata_functions.py    # Metadata tracking + Excel export
â”‚                 
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks (exploration, testing)
â”‚   â”œâ”€â”€ almacenamiento_bronze.ipynb
â”‚   â”œâ”€â”€ almacenamiento_silver.ipynb
â”‚   â””â”€â”€ almacenamiento_gold.ipynb
â”‚
â”œâ”€â”€ scripts/                     # Main pipeline scripts
â”‚   â”œâ”€â”€ bronze_layer.py
â”‚   â”œâ”€â”€ silver_layer.py
â”‚   â””â”€â”€ gold_layer.py
â”‚
â”œâ”€â”€ main.py                      # Orchestration script to run all layers
â”œâ”€â”€ README.md                    # Project documentation



---

## ğŸ§  Features

- ğŸ“¦ Delta Lake storage at every stage  
- ğŸ“„ Centralized metadata table with schema, layer, and history  
- ğŸ“Š Export metadata as Excel reports for traceability  
- ğŸ” Modular design for maintainability  
- âœ… Robust function design (try/except, docstrings)  
- ğŸ” Support for full and incremental extraction  

ğŸš€ **Clean, modular, and production-ready!**  
This weather data pipeline is built to evolve â€” add endpoints, integrate new layers, or scale for big data.

---

## ğŸ”® Future Improvements

âœ… Add **try/except** to make the code more robust.  
âœ… Improve documentation : add business-oriented documentation and technical-oriented documentation. 
âœ… Create a cron job to run automatically the script everyday  
âœ… Implement a more organized **monitoring, logging, and alerting system**.  
âœ… Add new APIs to enrich the data or use other endpoints of the Open-Meteo API:

- **ğŸ“ˆ Adzuna**: Job market data.  
- **âœˆï¸ Google Flights API**: Flight information.  
- **ğŸŒ¦ï¸ Weatherstack**: Alternative to Open-Meteo.  

